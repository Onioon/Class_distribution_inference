{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import MetaClassifier\n",
    "from model import MetaWithVar\n",
    "from model import DirectConnect\n",
    "from model import MetaClassifier4Layers\n",
    "from dataset import NetParasDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from scipy.signal import savgol_filter\n",
    "import scipy.stats as st\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "import prettytable\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the evaluation on the test set\n",
    "def eval_model(model, val_loader):\n",
    "    model.eval()\n",
    "    total_corr = 0\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    mseloss = nn.MSELoss()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for i,data in enumerate(val_loader):\n",
    "        l1,l2,l3,l4,label = data.get(\"L1\"), data.get(\"L2\"), data.get(\"L3\"), data.get(\"L4\"), data.get(\"Label\")\n",
    "        y_pred = model(l1.float(), l2.float(), l3.float(), l4.float())[0].squeeze()\n",
    "                \n",
    "        rl = mseloss(y_pred, label)\n",
    "        running_loss += rl.item()\n",
    "        print('BCE loss:' + str(rl.item()))\n",
    "        \n",
    "        y_pred = y_pred.detach().numpy()\n",
    "        label = label.detach().numpy()\n",
    "        predictions = np.append(predictions, y_pred)\n",
    "        labels = np.append(labels, label)\n",
    "        \n",
    "        x = np.array([i for i in range(len(label))])\n",
    "        plt.plot(label, \"o:\", linestyle='--', label='Target label')\n",
    "        plt.fill_between(x, label - 0.1, label + 0.1, alpha = 0.3 )\n",
    "        plt.plot(y_pred, \"o:\", linestyle='-', label='Predictions')\n",
    "        plt.gca().yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=1))\n",
    "        plt.xticks(range(0,200,5))\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value: Percentage of high income people')\n",
    "        plt.legend(loc = 'best')\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(20, 4)\n",
    "        plt.savefig('Predictions', dpi=500, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    for i in range(len(labels)):\n",
    "        if abs(labels[i]-predictions[i] <= 0.1):\n",
    "            correct += 1\n",
    "    \n",
    "    print('Accuracy:' + str(float(correct/200)))\n",
    "    \n",
    "    d = np.fabs(labels - predictions)\n",
    "    plt.scatter(labels, d, c = d, alpha = 0.4)\n",
    "    plt.colorbar()\n",
    "    plt.gca().xaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=1))\n",
    "    plt.gca().yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=1))\n",
    "    plt.xlabel('Target label')\n",
    "    plt.ylabel('Absolute Pure Error')\n",
    "    plt.savefig('Predictions and target', dpi=500, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.hist(labels - predictions,bins=50)\n",
    "    plt.gca().xaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=1))\n",
    "#     sns.distplot(labels - predictions, color='r')\n",
    "    plt.xlabel('Pure Error')\n",
    "    plt.ylabel('Number of samples')\n",
    "    plt.savefig('Quantities', dpi=500, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.hist(labels - predictions,bins=50, density=True, cumulative=True, label='CDF', histtype='step')    \n",
    "    plt.gca().xaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=1))\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ln(model, idx, lyn):\n",
    "    model.eval()\n",
    "    l1_10,l2_10,l3_10,l4_10 = torch.load('meta_train/' + str(idx) +'.pt')\n",
    "    n1 = model(l1_10.unsqueeze(0).float(), l2_10.unsqueeze(0).float(), l3_10.unsqueeze(0).float(), l4_10.unsqueeze(0).float())[lyn]\n",
    "    n1 = n1.detach().numpy().reshape(-1,1)\n",
    "    return n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ln_all(model, label, lyn):\n",
    "    n = get_ln(model, label, lyn)\n",
    "    for i in range(19):\n",
    "        n = np.concatenate((n, get_ln(model, label + i*100 +100, lyn)),axis = 0)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_ln(model, lyn):\n",
    "    n_10 = get_ln_all(model, 10, lyn)\n",
    "    n_30 = get_ln_all(model, 30, lyn)\n",
    "    n_50 = get_ln_all(model, 50, lyn)\n",
    "    n_70 = get_ln_all(model, 70, lyn)\n",
    "    n_90 = get_ln_all(model, 90, lyn)\n",
    "    \n",
    "    plt.hist(n_10,bins=50, density=True, cumulative=True, label='10%', histtype='step')  \n",
    "    plt.hist(n_30,bins=50, density=True, cumulative=True, label='30%', histtype='step')  \n",
    "    plt.hist(n_50,bins=50, density=True, cumulative=True, label='50%', histtype='step')\n",
    "    plt.hist(n_70,bins=50, density=True, cumulative=True, label='70%', histtype='step')  \n",
    "    plt.hist(n_90,bins=50, density=True, cumulative=True, label='90%', histtype='step')\n",
    "    \n",
    "    plt.scatter(np.mean(n_10), 0, c='C0',marker='x')\n",
    "    plt.text(np.mean(n_10),0, 'mean of 10%', rotation=45)\n",
    "    plt.scatter(np.mean(n_50),0, c='orange',marker='x')\n",
    "    plt.text(np.mean(n_50),0, 'mean of 50%', rotation=45)\n",
    "    plt.scatter(np.mean(n_90),0, c='forestgreen', marker='x')\n",
    "    plt.text(np.mean(n_90),0, 'mean of 90%', rotation=45)\n",
    "    \n",
    "    plt.scatter(np.mean(n_30),0,marker='x')\n",
    "    plt.text(np.mean(n_30),0, 'mean of 30%', rotation=45)\n",
    "    plt.scatter(np.mean(n_70),0, marker='x')\n",
    "    plt.text(np.mean(n_70),0, 'mean of 70%', rotation=45)\n",
    "    \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('The value of the weights of L' + str(lyn))\n",
    "    plt.ylabel('cdf')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.hist(n_10,bins=30, density=True,  label='10%', histtype='step')  \n",
    "    plt.hist(n_50,bins=30, density=True,  label='50%', histtype='step')\n",
    "    plt.hist(n_90,bins=30, density=True,  label='90%', histtype='step')\n",
    "    \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('The value of the weights of L' + str(lyn))\n",
    "    plt.ylabel('pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    table = prettytable.PrettyTable()\n",
    "    table.field_names = ['Percentage','Mean','Median','Variance']\n",
    "    table.add_row(['10%',np.mean(n_10),np.median(n_10),np.var(n_10)])\n",
    "    table.add_row(['50%',np.mean(n_50),np.median(n_50),np.var(n_50)])\n",
    "    table.add_row(['90%',np.mean(n_90),np.median(n_90),np.var(n_90)])\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_l1(model):\n",
    "    plt_ln(model, 1)\n",
    "    plt_ln(model, 2)\n",
    "    plt_ln(model, 3)\n",
    "    plt_ln(model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(NetParasDataset('meta_train/'), [1800, 200])\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1])\n",
      "torch.Size([16, 1])\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "tensor([0.4000, 0.7200, 0.9700, 0.2700, 0.8800, 0.7200, 0.0000, 0.5400, 0.5000,\n",
      "        0.0000, 0.5600, 0.5400, 0.3500, 0.5200, 0.9300, 0.9100],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b49feda77f17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2757\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2759\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "model = MetaWithVar()\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.02)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum = 0.5)\n",
    "model.train()\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    running_loss = 0 \n",
    "    for sample in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(sample.get(\"L1\"), sample.get(\"L2\"), sample.get(\"L3\"), sample.get(\"L4\"))[0].squeeze()\n",
    "#         print(output.shape)\n",
    "#         print(sample.get(\"Label\").shape)\n",
    "        print(output)\n",
    "        print(sample.get(\"Label\"))\n",
    "        loss = criterion(output, sample.get(\"Label\").float())\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        running_loss += loss.item()\n",
    "        # print('running loss:' + str(running_loss))\n",
    "    loss_list.append(running_loss*16/840)\n",
    "    plt.plot(loss_list)\n",
    "print(\"The last loss:{}\".format(loss_list[len(loss_list) - 1]))        \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('BCE Loss')\n",
    "plt.savefig('Loss.png', dpi=500, bbox_inches='tight')\n",
    "plt.show()\n",
    "eval_model(model, test_loader)\n",
    "plt_l1(model)\n",
    "\n",
    "# print('Accuracy on train set: {}'.format(accuracy(model, train_loader))) \n",
    "# print('Accuracy on test set: {}'.format(accuracy(model, test_loader))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "8aab16f10421cc2c2202fb59a2cb178f8887853341137f957a609f3c5cadd5e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
